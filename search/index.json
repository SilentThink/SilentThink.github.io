[{"content":"\n论文链接：https://arxiv.org/abs/2106.13423\ngithub仓库：https://github.com/Oxfordblue7/GCFL\nFederated Graph Classification over Non-IID Graphs 摘要 联邦学习中的图分类等图级任务，图可分布于不同本地系统。本文通过分析发现真实世界的图具有共同属性，但不同来源的图在结构和节点特征上呈现非独立同分布（Non-IID）。为此提出图聚类联邦学习（Graph Clustered Federated Learning, GCFL）框架，根据图神经网络（Graph Neural Network, GNN）的梯度动态聚类本地系统，以减少图的结构和特征异质性。同时观察到GCFL中GNN梯度波动影响聚类，进而设计基于动态时间规整（Dynamic Time Warping, DTW）的梯度序列聚类机制（GCFL+），实验验证了框架有效性。\n什么是非独立同分布（Non-IID）数据？ （ref:https://www.zhihu.com/question/395555567）\n维基百科：在概率论与统计学中，独立同分布（Independent and identically distributed，或称独立同分配，缩写为IID）是指一组随机变量中每个变量的概率分布都相同，且这些随机变量互相独立。一组随机变量独立同分布并不意味着它们的样本空间中每个事件发生概率都相同。例如，投掷非均匀骰子得到的结果序列是独立同分布的，但掷出每个面朝上的概率并不相同。\n独立：每次抽样之间没有关系，不会相互影响。比如你在随便丢骰子，每次抛到的数字是几就是几，是独立的。 但如果我要求你要两次抛到的数字和大于等于9，第一次和第二次抛就不独立，因为他们相互关联。\n同分布：你丢骰子，每次丢骰子到任何一个数字的概率都是1/6，是相等概率。或者说，在概率空间里面， 你不论进行几次抽样实验，他们都服从同样一个分布。又比如说，现在一个大小为pi的圆放在大小为4的 正方形，你丢一根针进去，结果分为在圆里面和圆外面。每次丢进这个圆的概率都是pi/4，你重复+∞次会 无限接近于这个pi/4.\n在联邦学习中，由于数据存储在不同的本地设备上，这些设备可能采集不同类型的数据、数据量不同、数据质量不同，或者数据在不同时间和地点收集，因此不同设备上的数据样本之间可能具有不同的分布特性或相关性，而不满足独立同分布的假设。\n**图数据的 Non - IID **:图数据在结构和特征方面存在显著的异构性，即不同客户端拥有的图数据在结构分布和节点特征分布上不遵循相同的模式。\n1. 引言 联邦学习允许本地系统在保护数据隐私的同时受益于其他系统的数据，但面临数据分布异质性问题。本文研究发现不同来源的真实世界图存在共同属性，但也存在结构和特征异质性，因此提出GCFL框架，根据GNN梯度聚类客户端以降低异质性，并进一步改进为GCFL+以应对梯度波动问题。\n真实世界图数据的共性与异构性：\n通过对不同领域的真实世界图数据集（如 PTC_MR（分子结构）、ENZYMES（蛋白质结构）、IMDB - BINARY （社交社区）和 MSRC_21（超像素网络））的初步数据分析，发现它们在某些图属性上（如节点度分布的峰度、平均最短路径长度、最大连通分量大小和聚类系数）与随机图相比具有显著的共性，这为跨数据集和跨领域的联邦学习提供了可能性。\n然而，不同数据集或领域的图在详细结构和节点特征上仍存在差异，表现出结构和特征的异构性，这种异构性在跨数据集的联邦学习设置中被称为 Non - IID 图，可能导致传统联邦学习算法（如 FedAvg）失效。\n度量指标解释：\n峰度（Kurtosis）：用于衡量数据分布的陡峭程度或峰值的尖锐程度。在节点度分布中，较大的峰度值（如文中提到的 ENZYMES、IMDB - BINARY 和 MSRC_21 数据集）表明节点度呈现长尾分布，即少数节点具有非常高的度，而大多数节点的度相对较低。这种分布特征可能对图的结构和功能产生重要影响，例如在社交网络中，少数高度连接的节点（如意见领袖）可能对信息传播起着关键作用；在生物网络中，高连接度的节点可能代表着关键的生物分子或功能模块。 平均最短路径长度（avg.shortest path length）：是指图中所有节点对之间最短路径长度的平均值。PTC_MR、ENZYMES 和 MSRC_21 数据集尽管实际图的大小差异较大，但具有相似的平均最短路径长度。这一属性反映了图中节点之间的连接紧密程度或信息传递的效率。在一些网络中，较短的平均最短路径长度可能意味着信息能够快速传播，例如在互联网路由网络中，较短的路径长度有助于减少数据传输延迟；而在其他网络中，较长的路径长度可能表示网络具有更高的层次结构或模块化程度，如生物代谢网络中，不同的代谢途径可能通过较长的路径相互连接。 聚类系数（Clustering Coefficient，CC）：衡量图中节点聚集程度的指标，即节点的邻居之间相互连接的紧密程度。ENZYMES、IMDB - BINARY 和 MSRC_21 数据集具有较大的聚类系数，这意味着这些图中存在较多的三角形结构或节点聚类现象。在社交网络中，高聚类系数可能表示社交圈子内的成员之间联系紧密，信息容易在小群体内传播；在生物网络中，高聚类系数可能暗示着生物分子之间存在功能相关的模块或复合物。 最大连通分量大小（Largest Component Size，LC）：表示图中最大连通分量（即相互连接的节点集合）所占的比例。几乎所有数据集都观察到较大的 LC 值，这表明这些图在很大程度上是连通的，即大多数节点可以通过路径相互到达。在一些网络应用中，高连通性是确保信息或资源能够在整个网络中有效传播和共享的关键，例如在电力网络中，高连通性有助于维持电力供应的稳定性；而在某些情况下，较低的连通性可能意味着网络存在瓶颈或脆弱点，如交通网络中的拥堵路段可能导致局部连通性下降。 差异显著性指标：\n真实值（real）：指的是对实际的真实世界图数据集（如 PTC_MR、ENZYMES、IMDB - BINARY、MSRC_21 等）进行测量得到的相应图属性的值。例如，对于 PTC_MR 数据集的度分布峰度，其真实值为 2.1535，这是通过对该数据集中所有图的节点度分布进行计算得出的实际峰度数值。\n随机值（random）：表示使用 Erdős–Rényi 模型生成的具有相同节点数量和链接数量的随机图的相应图属性的值。该模型是一种生成随机图的经典方法，通过随机连接节点来构建图结构。对于每个真实数据集，都生成了具有相似规模（节点和链接数量相同）的随机图，并计算其图属性，作为对比基准。例如，与 PTC_MR 数据集对比的随机图的度分布峰度为 2.4424。\np-value:用于衡量真实数据集的图属性与随机图的图属性之间差异的显著性水平。它是在假设检验中使用的一个统计量，用于判断观察到的差异是由于随机因素还是真实存在的系统性差异导致的。\n较小的 p - value表明真实数据集的图属性与随机图的图属性之间的差异在统计上是显著的，即不太可能是由随机因素引起的。例如，ENZYMES 数据集的度分布峰度的 p - value 为 0.0027，这意味着其与随机图在峰度上的差异是显著的，说明 ENZYMES 数据集的节点度分布具有与随机图不同的、特定的结构特征。 较大的 p - value（接近 1）则表示真实数据集和随机图在该图属性上的差异不显著，可能是由于随机波动导致的，不能确定真实数据集具有特殊的结构或模式。如 PTC_MR 数据集的度分布峰度的 p - value 为 0.9999，说明其与随机图在峰度方面的差异不具有统计学意义，即从这个指标来看，PTC_MR 数据集的节点度分布在结构上与随机图较为相似，没有明显的特殊结构特征被检测到。 2. 相关工作 2.1联邦学习 联邦学习在数据分布于远程设备且模型由中央服务器协调训练的场景下受到关注。FedAvg是首个基本FL算法，但在处理非IID数据时存在收敛慢、精度下降等问题。已有研究从数据共享、优化收敛、个性化学习、聚类学习等方面进行改进，但仍面临挑战。\n水平联邦学习：\nFedAvg:联邦学习的开山之作：\n论文地址：https://proceedings.mlr.press/v54/mcmahan17a/mcmahan17a.pdf 源码地址：https://github.com/shaoxiongji/federated-learning\n**针对的问题：**移动设备中有大量的数据，但显然我们不能收集这些数据到云端以进行集中训练，所以引入了一种分布式的机器学习方法，即联邦学习Federal Learning。在FL中，server将全局模型下放给各client，client利用本地的数据去训练模型，并将训练后的权重上传到server，从而实现全局模型的更新。\n算法介绍：\n联邦随机梯度下降算法（FedSGD） 设定固定的学习率 $\\eta$，对 $K$ 个客户端（client）的数据计算损失梯度： $$ g_k = \\bigtriangledown F_k(w_t) $$服务器（server）将聚合每个客户端计算的梯度，以此来更新模型参数： $$ w_{t+1} \\leftarrow w_t - \\eta \\sum\\limits_{k=1}^K \\frac{n_k}{n} g_k = w_t - \\eta \\bigtriangledown f(w_t) $$FedSGD 的不足之处：\n高通信成本：\nFedSGD 要求每个客户端在每次迭代中计算一次梯度后立即与服务器同步更新模型参数。对于大规模联邦学习系统，每个客户端频繁通信会带来高昂的网络开销和延迟，尤其在客户端数量较多或带宽有限的情况下。 这种设计在实际中会导致资源消耗大，且模型参数更新效率低下，系统负载明显。 对本地数据的利用不足：\nFedSGD 在客户端每次只进行一次梯度计算，无法充分利用客户端的本地数据。这样每次更新依赖的样本量有限，导致每个客户端传回的梯度更新效果有限，模型难以高效逼近最优解。 尤其在数据分布存在差异的场景下（非IID情况），一次梯度更新很难反映出本地数据的整体特征。 非独立同分布（Non-IID）数据适应性差：\n在联邦学习中，客户端的数据分布通常非独立同分布，各客户端的样本特性可能差异较大。FedSGD 将所有客户端的一次梯度直接聚合，未考虑到各客户端数据分布的差异，这会导致模型收敛效果不佳。 由于梯度更新频繁，FedSGD 的模型在这种场景下容易受到局部梯度波动的影响，难以平衡不同客户端的数据贡献。 收敛速度较慢：\nFedSGD 的一次更新只包含每个客户端单次计算的梯度，信息量较少，导致模型收敛缓慢。在同样的通信轮数下，FedSGD 无法充分逼近全局最优解。 由于不能在本地多轮迭代优化，FedSGD 对客户端的计算资源利用率较低，浪费了部分算力。 联邦平均算法（FedAvg） FedAvg 针对上述不足之处做出改进：\n减少通信频率：FedAvg 允许客户端在本地训练多轮后再上传更新结果，大大降低了每次通信所需的频率。 充分利用本地数据：客户端可以在本地多轮更新权重，充分利用本地数据特征，使得更新后的模型更具泛化性。 更好的适应非IID数据：FedAvg 使用权重加权平均，能够更好地整合不同客户端的模型，降低数据分布差异带来的负面影响。 加速收敛：通过本地多轮迭代，FedAvg 使得模型在每次通信时都能积累更多优化信息，从而在较少通信轮次下获得更好的收敛效果。 算法流程如下：\n给定$K$个客户端，在第t轮训练过程中：\n中心服务器随机选择部分客户端 客户端从中心服务器下载模型根据本地数据训练$E$轮 各个客户端发送训练后的参数到中心服务器，中心服务器根据下式更新参数： 其中$ n_k $为客户端$k$样本数，$n$为所有客户端的样本总数。 在客户端进行局部模型的更新： $$ w_{t+1}^k \\leftarrow w_t - \\eta g_k $$服务器对每个客户端更新后的权重进行加权平均： $$ w_{t+1} \\leftarrow \\sum_{k=1}^K \\frac{n_k}{n} w_{t+1}^k $$ $n_k$ 是 客户端 \\( k \\) 的数据样本数量。 $ \\eta $ 是学习率 注意：每个客户端可以在本地独立地多次更新本地权重，然后将更好的权重参数发给服务器进行加权平均。这样做的好处是不用每更新一次就去聚合，从而大大减少了通信量。\nFedAvg 的计算量：\nFedAvg 的计算量与以下三个参数有关：\n$C$：每轮训练选择客户端的比例，即每一轮通信时只选择 $C \\times K$ 个客户端；（$K$ 为客户端总数） $E$：每个客户端更新本地权重时，在本地数据集上训练 $E$ 轮； $B$：客户端更新权重时，每次梯度下降所使用的数据量，即本地数据集的 batch size； 每次从训练集中随机抽取一定数量的数据样本（即 Batch Size）进行梯度计算，这种方法能够在保证收敛速度的同时节省计算资源，是最常用的优化方式。\n特例关系：\nFedSGD 是 FedAvg 的一个特例，即当参数 $E = 1$，$B = \\infty$ 时，FedAvg 等价于 FedSGD。\n注：$B = \\infty$ 表示 batch size 大小就是本地数据集大小。\n2.2联邦学习在图数据上的应用 已有研究将FL应用于图数据，但多数研究集中于节点分类和链接预测，无法直接应用于图分类任务。本文研究跨数据集/跨域的联邦图分类，具有创新性。\n3. 预备知识 3.1图神经网络 GNN通过消息传递和邻域聚合学习图表示，如节点嵌入或图嵌入，可用于图分类等任务。\n3.2 FedAvg算法 FedAvg是基本的FL算法，通过聚合本地客户端更新的模型参数并重新分发平均参数来训练模型，但在处理非IID数据时存在不足。\n4. GCFL框架 4.1跨客户端的Non-IID数据结构与特征分析 异构性度量标准 结构异构性度量：使用AEWs(Anonymous Walk Embeddings)生成每个图的表示，计算各个图AWE表示之间的Jensen-Shannon距离。 特征异构性度量：计算各个图内部节点之间特征相似性的经验分布，计算各个图特征相似性经验分布之间的Jensen-Shannon散度。 数据集分析 如表2所示，单一数据集、单一领域及不同领域内的图数据在结构和特征上均表现出不同程度的异构性，其中结构异构性使得模型难以学习到不同客户端之间重要的相似图模式，而特征异构性则使得模型难以学习到在不同客户端之间具有泛化能力的消息传递机制。\n数据集列\n：列举了不同的数据集组合情况，用于对比不同数据集之间以及同一数据集内部的异质性。\nIMDB - BINARY (social)：单独列出此数据集，可观察该社会网络数据集内部图之间的异质性情况。 cox2 (molecules)：单独列出分子结构数据集 cox2，用于分析其内部图的异质性。 cox2 (molecules) 与其他分子数据集（如 PTC_MR、ENZYMES）组合：展示了分子数据集之间的异质性比较，有助于了解分子结构数据集在不同组合下的结构和特征差异。 cox2 (molecules) 与社会网络数据集（如 IMDB - BINARY）组合：体现了分子数据集与社会网络数据集之间的跨域异质性，这种组合可用于研究不同领域数据集之间的相似性和差异性。 结构异质性（avg. struc. hetero.）列\n数值含义：使用匿名游走嵌入（Anonymous Walk Embeddings, AWEs）方法为每个图生成表示，然后计算每对图的 AWEs 之间的 Jensen - Shannon 距离，以此作为结构异质性的度量。该值越大，表示图之间的结构差异越大。 数据示例分析 IMDB - BINARY (social) 的 0.4406 (0.0397)：表示该社会网络数据集内部图之间存在一定程度的结构异质性。括号内的 0.0397 可能是某种度量的标准差或误差范围，说明在该数据集内不同图的结构差异存在一定的波动，但整体平均结构异质性为 0.4406。 cox2 (molecules) 与 PTC_MR (molecules) 组合的 0.3689 (0.0540)：表明这两个分子数据集之间的结构异质性相对其内部异质性有所增加，但仍处于一定范围内，说明分子数据集之间虽然存在结构差异，但在某些方面仍具有一定相似性，与单独的社会网络数据集相比，分子数据集之间的结构差异相对较小。 特征异质性（feat. hetero.）列 数值含义：通过计算每个图中所有链接节点对之间的特征相似性的经验分布，然后计算每对图的特征相似性分布之间的 Jensen - Shannon 散度，作为特征异质性的度量。该值越大，表示图之间的特征差异越大。 数据示例分析 IMDB - BINARY (social) 的 0.1785 (0.1226)：说明该社会网络数据集内部图在特征方面存在一定的异质性，且特征差异的波动范围由括号内的 0.1226 表示，可能暗示数据集内不同图的节点特征分布存在一定变化。 cox2 (molecules) 与 IMDB - BINARY (social) 组合的 0.1837 (0.1065)：显示分子数据集与社会网络数据集之间的特征异质性程度，表明跨域数据集在特征方面存在明显差异，与分子数据集内部或社会网络数据集内部的特征异质性相比，跨域时特征差异更为显著。 GCFL 结构 中央服务器与本地客户端：GCFL 包含一个中央服务器和一组本地客户端{S₁, S₂,..., Sn}。 动态聚类：服务器可将客户端动态聚类为一组集群{C₁, C₂,...}，并维护m个集群级别的模型。 本地客户端的图数据：每个本地客户端Sᵢ拥有一组图Gᵢ = {G₁, G₂,...}，其中每个图数据样本Gⱼ = (Vⱼ, Eⱼ, Xⱼ, yⱼ) ∈ Gᵢ，包含一组节点Vⱼ、一组边Eⱼ、节点特征Xⱼ和一个图类别标签yᵢ。 任务与目标 任务：每个本地客户端Sᵢ的任务是进行图分类，即对于每个图Gⱼ ∈ Gᵢ预测类别标签yⱼ = hₖ(Gⱼ)，其中hₖ是本地客户端Sᵢ所属的集群Cₖ的协作学习的最优图挖掘模型。 目标：最小化所有集群{Cₖ}的损失函数$F(\\Theta_k):=\\mathbb{E}_{S_i\\in C_k}[f(\\theta_k;G_i)]$，其中函数f(θₖ; Gᵢ)是属于集群Cₖ的客户端Sᵢ的局部损失函数。同时，维持基于联邦学习过程的动态集群分配Γ(Sᵢ) → {Cₖ}。 问题的核心挑战 处理数据异构性 如何在客户端图数据存在结构和特征异构性（如在不同数据集、领域内图的结构和特征差异）的情况下，有效地进行模型训练。异构性使得传统联邦学习算法难以直接应用，因为它们通常假设数据是独立同分布的，而这里需要找到一种方法来适应不同客户端的数据分布差异，以实现有效的协同训练。 动态聚类与模型优化 确定如何动态地将客户端聚类，使得在每个簇内数据的异构性降低，同时在整个联邦学习过程中能够根据数据和模型的变化动态调整簇的划分。并且，在聚类的基础上，如何优化每个簇内的模型训练，以提高图分类的准确性，这需要考虑如何在不同簇之间平衡模型的个性化和全局共享信息的利用，避免过度拟合某个簇的数据而失去泛化能力。 4.3技术设计 GCFL利用GNN的强大表示能力，根据客户端传输的梯度动态聚类。通过引入超参数$\\varepsilon_1$和$\\varepsilon_2$作为聚类准则，当满足条件时，服务器基于余弦相似度矩阵和Stoer-Wagner最小割算法对集群进行二分。客户端在本地训练后传输梯度，服务器聚合梯度更新模型参数。\n选择GNNs作为图挖掘模型：GNNs在学习图表示方面能力强大且广泛应用于图挖掘，其模型参数和梯度能反映图结构与特征信息（详见4.4节），因此被用于GCFL框架。 动态聚类机制 聚类依据：当客户端数据分布高度异构时，通用联邦学习（FL）接近平稳点时，客户端传输梯度范数不全趋于零。引入超参数 $\\varepsilon_1$ 判断是否接近平稳点（$\\delta_{\\text{mean}} = \\left|\\sum_{i \\in [n]} \\frac{\\left|\\mathcal{G}{i}\\right|}{|\\mathcal{G}|} \\Delta \\theta{i}\\right| \u0026lt; \\varepsilon_{1}$），同时若存在客户端梯度范数较大，引入 $\\varepsilon_2$ 决定是否分裂簇（$\\delta_{\\text{max}} = \\max\\left(\\left|\\Delta \\theta_{i}\\right|\\right) \u0026gt; \\varepsilon_{2} \u0026gt; 0$）。 聚类过程：GCFL采用自上而下的二分机制。在通信轮次 $t$ 时，服务器接收不同簇客户端的梯度，若某簇 $C_k$ 满足分裂条件，计算簇内余弦相似度矩阵 $\\alpha_k$ 构建全连接图，用Stoer-Wagner最小割算法将该簇二分为 $C_{k1}$ 和 $C_{k2}$。此机制可自动动态确定簇的数量，超参数可通过验证集实验进行设置。 客户端与服务器交互 簇 $C_k$ 中的客户端 $S_i$ 寻找接近真实解 $\\theta_{k, i}^*$ 的 $\\hat{\\theta}{k, i}$，在轮次 $t$ 将梯度 $\\Delta \\theta{k, i}^{t} = \\hat{\\theta}{k, i}^{t} - \\theta{k, i}^{t - 1}$ 传输给服务器。 服务器维护簇分配，并按簇聚合梯度：$\\theta_{k}^{t + 1} = \\theta_{k}^{t} + \\sum_{i \\in [n_{k}]} \\Delta \\theta_{k, i}^{t}$。 然后，服务器将更新后的参数$\\theta_{k}^{t+1}$广播回簇 $C_k$ 内的客户端 符号含义\n$F(\\Theta_k)$：表示与簇 $C_k$ 相关的整体损失函数。它是一个关于簇 $C_k$ 内所有客户端模型参数 $\\theta_{k, i}$ 的函数。这里的 $\\Theta_k$ 可以理解为簇 $C_k$ 内所有客户端模型参数的集合。\n$E_{S_i \\in C_k}$：表示在簇 $C_k$ 内对所有客户端 $S_i$ 的期望。它意味着要考虑簇 $C_k$ 内每个客户端的情况，并对它们的某种统计量（在这里是损失函数 $f(\\theta_{k, i}; G_i)$）进行平均或综合考虑。\n$f(\\theta_{k, i}; G_i)$：表示属于簇 $C_k$ 的客户端 $S_i$ 的局部损失函数。这个函数衡量了客户端 $S_i$ 在使用其本地图数据 $G_i$ 和模型参数 $\\theta_{k, i}$ 时，模型预测与真实标签之间的差异程度。具体的形式取决于所使用的图分类模型和损失函数的定义。例如，在分类任务中，若使用交叉熵损失函数，$f(\\theta_{k, i}; G_i)$ 会根据模型对图 $G_i$ 的预测概率分布和真实的类别标签 $y_i$ 来计算两者之间的差异。\n$\\theta_{k, i}$：是簇 $C_k$ 内客户端 $S_i$ 的模型参数。在图神经网络（GNN）用于图分类的情况下，这些参数决定了 GNN 如何对图的结构和特征进行学习和表示，并进行分类预测。例如，在 GNN 的消息传递和聚合过程中，参数 $\\theta_{k, i}$ 会影响节点特征的更新和图级别的表示计算。\n$G_i$：是客户端 $S_i$ 拥有的一组图数据。每个图 $G_j = (V_j, E_j, X_j, y_j) \\in G_i$ 包含节点集合 $V_j$、边集合 $E_j$、节点特征 $X_j$ 和图类别标签 $y_j$。这些图数据是计算局部损失函数 $f(\\theta_{k, i}; G_i)$ 的基础，模型根据这些图数据进行训练和预测，并通过损失函数来评估预测的准确性。\n4.4理论分析 梯度反映信息：通过Bourgain定理证明GNN梯度能够反映图的结构、特征和任务信息，从而理论上支持基于梯度的聚类框架GCFL可捕获结构和特征信息。 结构与特征差异捕获：针对结构和特征差异的两个命题，证明了不同结构或特征的图在训练SGC时，权重差异与结构/特征差异有界，即梯度会随结构和特征变化。 任务异质性捕获：命题表明不同任务训练下，SGC权重有界，意味着GCFL框架有潜力扩展到跨任务图级联邦学习。 5. GCFL+：基于梯度观测序列改进的GCFL GCFL+相关内容 梯度范数波动问题（5.1）\n波动现象描述：在观察GCFL框架中每个通信轮次的梯度范数时，发现其存在两个明显问题。一是梯度范数持续波动，二是不同客户端的梯度范数尺度存在差异。这种波动和尺度差异表明客户端梯度的更新方向和距离各不相同，再次体现了设置中结构和特征的异质性。 对GCFL聚类的影响：在原始GCFL框架中，服务器在聚类标准满足时仅基于最后传输的梯度计算余弦相似度矩阵。然而，由于梯度范数在通信轮次中波动，尽管有聚类标准约束，基于单个梯度点的GCFL聚类可能会忽略重要的客户端行为，并受到噪声干扰。例如在图1（a）中，GCFL在第119轮根据该轮梯度进行聚类，但未能有效找到异质性较低的图。 GCFL+的技术设计（5.2）\n针对上述问题，提出改进的GCFL+。服务器维护一个多变量时间序列矩阵 $Q \\in \\mathbb{R}^{n, d}$（其中 $n$ 为客户端数量，$d$ 为跟踪的梯度序列长度）。在每轮通信 $t$ 时，将梯度范数 $\\left|\\Delta \\theta_{i}^{t}\\right|$ 添加到 $Q(i, :)$ 并移除过期数据。GCFL+采用与GCFL相同的聚类标准（公式4和5），当满足条件时，服务器使用动态时间规整（DTW）技术计算距离矩阵 $\\beta$，其元素为两两梯度序列的距离。对于簇 $C_k$，服务器通过 :\n$$\\beta_{k}(p, q) = \\text{dist}(Q(p, :), Q(q, :))$$（其中 $p, q \\in \\text{idx}({S_{i}})$，$\\text{idx}({S_{i}})$ 为簇 $C_k$ 中所有客户端 ${S_{i}}$ 的索引）\n计算各客户端之间的距离。\n基于此距离矩阵，服务器对满足聚类标准的簇进行二分。如图1(b)所示，GCFL+在第118轮基于长度为10的梯度序列进行聚类，能捕捉客户端更长期的行为，形成更同质的簇。\n通过这些改进，GCFL+旨在克服GCFL在处理梯度波动时的不足，提高聚类质量，从而在联邦图分类任务中取得更好的性能，尤其是在面对具有结构和特征异质性的非独立同分布图数据时。\n6. 实验 6.1实验设置 数据集：使用13个来自三个领域的图分类数据集，设计单数据集和多数据集两种数据划分机制，每个客户端持有一定数量图，部分用于测试。 基线方法：使用self-train、FedAvg和FedProx作为基线方法，图分类模型采用GIN，固定架构和超参数以控制实验。 参数设置：详细说明GIN网络参数、优化器、学习率、权重衰减等设置，以及FL方法的本地轮数，通过离线训练确定聚类准则超参数。 6.2实验结果 单数据集内联邦图分类：GCFL和GCFL+在该设置下显著提升图分类性能，相比self-train有明显性能增益，帮助更多客户端提升性能，而FedAvg仅能帮助约一半客户端，表明传统FL算法在单数据集图数据上因非IID性存在局限。 跨多数据集联邦图分类：该设置下客户端异质性更强，GCFL和GCFL+仍能有效提升性能，GCFL+相比FedAvg能使更多客户端受益，且在多数据集设置中，两者均能显著降低集群内结构和特征异质性，不同领域数据集也能相互受益，体现了框架的有效性。 超参数影响：$\\varepsilon_1$和$\\varepsilon_2$分别为停止准则和聚类控制参数，在合理范围内变化对GCFL和GCFL+性能影响较小。 6.3集群内结构和特征分析 GCFL和GCFL+聚类后显著降低集群内图的结构和特征异质性，尤其在多数据集设置中。同一数据集内特征异质性降低较少，结构异质性显著降低；多数据集设置中两者均显著降低。聚类结果显示来自同一领域的数据集更易聚在一起，但不同领域数据集也能相互受益，表明框架能根据性能动态聚类的必要性。\n","date":"2024-11-09T14:11:41+08:00","permalink":"https://SilentThink.github.io/p/%E9%9D%9E%E7%8B%AC%E7%AB%8B%E5%90%8C%E5%88%86%E5%B8%83%E5%9B%BE%E4%B8%8A%E7%9A%84%E8%81%94%E9%82%A6%E5%9B%BE%E5%88%86%E7%B1%BB/","title":"非独立同分布图上的联邦图分类"},{"content":"\n论文链接：http://joces.nudt.edu.cn/CN/Y2020/V42/I01/89\n图数据压缩技术综述 1 引言 随着大数据时代的到来，数据规模以前所未有的方式不断增长，数据结构也呈现出复杂性和多样性。图，作为一种特殊的数据结构在众多领域有重要的研究价值。\n随着图在各个领域的广泛应用，传统的图存储结构已经不能支持超大规模图数据的管理和分析。中国互联网络中心 2018 年发布的《第 41 次中国互联网络发展状况报告》 中提到， 网页的数量约为2600亿。若采用图模型存储上述网页节点及节点关系， 至少需要 42TB 的存储空间，并且随着因特网的不断发展，需要的存储开销也越来越大。如何存储和操作上亿万个节点的图数据的问题受国内外研究人员广泛研究。\n图数据压缩技术：主要思想是消除图数据中的冗余信息，将图数据以压缩的形式存储到内存中。\n本文主要从3个方面讨论图数据压缩技术：\n（1）基于邻接矩阵的压缩技术：主要思想是尽可能地压缩邻接矩阵中的“0” 元素。\n（2）基于形式化方法的压缩技术： 主要思想是对所给的图进行编码\u0026quot; 使其转化为布尔代数\u0026quot; 再利用决策图对布尔代数进行表示和化简。\n（3）基于邻接表的压缩技术： 主要思想是利用节点的邻居节点集的相似性和局部引用性来进行压缩。\n2 基于邻接矩阵的压缩技术 （1）k²-tree 压缩技术 构造过程 步骤 1：对于给定的邻接矩阵，判断是否为的幂。若是，进入步骤 2；若不是，增加行和列使（为正整数），新增元素用 “0” 填充，再进入步骤 2 递归划分。 步骤 2：依据 MXQuntree 规则把矩阵划分为个大小一致的子矩阵。若子矩阵至少有一个 “1” 元素，标记为 1，否则标记为 0，自上而下、自左而右排列这些值作为根节点的 4 个儿子节点，完成树的第 1 层节点构造。对标记为 1 的矩阵递归处理，其值作为树的第 2 层节点，重复直至划分后的矩阵全为 0 或已划分到原始矩阵元素，递归停止。 示例及优势：以图1中 4 个节点的网页图和 图2中11 个节点的网页图为例，11 个节点网页图用邻接矩阵存储需 121bit，用k²-tree 存储需 72bit，可见k²-tree 空间利用率更高，且节点数增加时节省空间更多，还支持常数时间内查询节点直接邻居和反向邻居。 存在问题 网页图中节点和链接分布依赖 URL 排序，传统k²-tree 机械划分会使稠密和稀疏区域在同子矩阵，降低空间利用率。 k²-tree 邻居查询时间与树高度成正比，处理上亿节点图数据时，若不处理，邻居查询时间大幅增加。 （2）k²-partition 技术 改进思路：Claude 等人利用网页图中域的规律，提出k²-partition，沿对角线划分图为不同域，对不同域用传统-tree 表示，实现较好时间 / 空间均衡。 效果对比：如对图 2 中的矩阵，传统k²-tree 表示需 72bit 存储空间，k²-partition 表示只需 64bit，且随图节点增加效果更明显，同时能获得更好查询时间。 （3）kᵈ-tree 技术 提出背景及构造：Caro 等人针对多维数据紧凑表示需求，利用 $k^2$-tree 构造思想提出 $k^d$-tree。它是 $k^2$-tree 的一般化形式，用于表示 $d$ 维二元矩阵，将规模为 $n_1 \\times n_2 \\times \\cdots \\times n_d$ 的 $d$ 维矩阵递归划分为 $k^d$ 个子矩阵。假设 $n_i = n$（$1 \\leq i \\leq d$），每个树节点有 $k^d$ 个儿子节点表示子矩阵，按从高维到低维次序确定 $k^d$-tree 各层值。 示例说明：图 5 展示了不同维度下 $k^d$-tree（$k = 2$）的表示方法。 3 基于形式化方法的压缩技术 （1）有序二叉决策图（OBDD） 核心思想：杨志飞等人将符号计算运用到大规模图数据压缩表示中，把图中节点二进制编码，链接关系转布尔代数，再用 OBDD 求解。利用布尔代数节点取值冗余，通过 OBDD 化简和删除规则共享子图以提高存储效率。在这种表示下，图的多种操作可转化为 OBDD 的相关操作。例如，查询节点度数可转化为 OBDD 的可满足性问题等。 示例：对于有 $n$ 个节点的有向图，用布尔变量编码节点和边转化为布尔表达式。例如，对于 4 个节点有向图（设为图 $G$），需要 2 个布尔变量（设为 $x_1, x_2$ 和 $y_1, y_2$）分别表示有向边的起点和终点。若节点 0（编码为 $x_1\u0026rsquo;x_2\u0026rsquo;$，即 $x_1 = 1, x_2 = 1$）到节点 1（编码为 $y_1\u0026rsquo;y_2\u0026rsquo;$，即 $y_1 = 1, y_2 = 1$）有一条有向边，则表示为 $x_1\u0026rsquo;x_2\u0026rsquo;y_1\u0026rsquo;y_2\u0026rsquo;$。编码每条边即可得到图 $G$ 对应的 OBDD（如图 6b）。 缺陷：但 OBDD 终节点只能为 0 或 1，因此只能表示无权图。 （2）代数决策图（ADD） 拓展内容：Bahar 等人提出 ADD，将布尔代数拓展到伪布尔代数，将无权图拓展到带权图，丰富了图的布尔代数表示方法。其将图转化为 ADD 的思想与 OBDD 类似，但 ADD 的终节点是图中边的权重值。例如，4 个节点带权有向图（设为图 $H$）对应的邻接矩阵 $M_G$ 及代数决策图（如图 7）所示。 （3）k²-MDD 技术 提出背景及构造：针对 $k^2$-tree 存在同构子树、只能压缩稀疏图和表示静态图等问题，董荣胜等人将多值决策图（MDD）与 $k^2$-tree 结合，提出了 $k^2$-MDD。构造过程分三步：\n步骤 1：将邻接矩阵用传统 $k^2$-tree 表示。\n步骤 2：删除 $k^2$-tree 中所有 0 节点，合并叶子节点中为 1 的节点。\n步骤 3：对 $k^2$-tree 每个分支进行二进制编码（$k = 2$），合并节点值相等且儿子节点相同的节点（共享子图）。\n例如，11 个顶点邻接矩阵的 $k^2$-tree 表示（如图 8）、传统 $k^2$-tree 的同构子树分布（如图 9）及 $k^2$-tree 的 MDD 表示（如图 10）展示了其构造过程及效果。\n（4）技术优势总结 实验对比（如用真实网页图和社交网络数据集）表明，在 $k^2$-tree、$k^2$-MDD 和 OBDD 中，用位串 $T$ 记录除最后一层节点的 0 值和 1 值，位串 $L$ 记录最后一层节点的 0 值和 1 值，$T$ 和 $L$ 的总和为存储空间。以网页图数据集（如 $cnr, in, uk, indochina$）和社交网络数据集（如 $enron, dblp-1, dblp-2, dewiki$）为例，采用 OBDD 压缩网页图，$T$ 和 $L$ 的总和约为 $k^2$-tree 的 21%；采用 $k^2$-MDD 压缩网页图，$T$ 和 $L$ 的总和约为 $k^2$-tree 的 3%。在社交网络数据集上也有类似结果，显著改善了存储空间需求，体现了形式化方法在大规模图数据压缩处理上的优势。 4 基于邻接表的压缩技术 （1）空隙编码 编码依据及思想：研究表明多数网页图具有局部性，即页面直接邻居集合挨得很近。Boldi 等人据此提出空隙编码，其思想是用连续节点标签值替代原始值以压缩节点标签，减少存储空间。设 $A(x)=(a_1, a_2, a_3, \\cdots, a_n)$ 为第 $x$ 个节点的直接邻居标签值序列，$x$ 对应的空隙编码 $B(x)=(c(a_1 - x), a_2 - a_1 - 1, a_3 - a_2 - 1, \\cdots, a_n - a_{n - 1} - 1)$，其中 $$ c(x)=\\begin{cases}2x, \u0026 x \\geq 0 \\\\ 2|x| - 1, \u0026 x \u003c 0\\end{cases} $$ 例如，对于网页图邻接表（如表 1），可得到对应的空隙编码（如表 2）。\n（2）参考压缩 压缩原理：利用网页的相似性，即位置较近的网页的后继集较为相似。Suel 等人提出参考压缩，用一个节点的邻接表表示其余邻接表。设 $s(x)$ 为参考表，$s(y)$ 为复制表，$y - x$ 为参考系数 $r$。若 $s(x)$ 的后继在 $s(y)$ 中存在，复制表的对应位置为 $1$，否则为 $0$，$s(y)$ 中不在 $s(x)$ 中的后继为额外节点。例如，网页图邻接表的参考压缩如表 3 所示。但上述两种技术要求节点直接邻居集合有序，若需保存原始链接顺序则不适用。 （3）Repair 算法 算法思想及操作：Adler 和 Faust 等人发现邻接表节点后继存在相似信息，提出了 Repair 算法。该算法将所有节点后继看成序列 $T$，每次用未在 $T$ 中出现的符号 $s$ 替换 $T$ 中最频繁的符号对，直到 $T$ 中无频繁模式为止。设图 $G=(V, E)$，则 $T(G)=v_1v_{1,1}v_{1,2}v_{1,3}\\cdots v_{1,n}v_2v_{2,1}v_{2,2}v_{2,3}\\cdots v_{2,n}\\cdots v_nv_{n,1}v_{n,2}v_{n,3}\\cdots v_{n,n}$，$Ptrs[m]$ 记录节点在 $T$ 中的起始位置。例如，给定图邻接表的 Repair 压缩如图 11 所示。该算法将邻接表压缩成字典规则集合 $R$、指针数组 $Ptrs$ 和序列 $T$。查询节点信息时，仅需部分解压缩即可。但对于大规模图，由于每次添加新规则导致字典规则集合增大，Bille 等人改进了该算法，取得了较好的时间和空间平衡。 （4）LZ78 算法 算法流程及特点：另一种基于邻接表的压缩算法 LZ78 由 Ziv 和 Lempel 提出，思想是建立字典表，读入字符时判断是否在表中。若不在，保存字符并建立索引；若在，保存索引并添加新字符形成字符串表示。具体流程如下：先建立空字典表，依次读取新字符 $c$，查找当前前缀 $P$ 与 $c$ 的组合 $P + c$。若 $P + c$ 在字典表中，更新前缀 $P$ 为 $P + c$；若不在，输出当前前缀索引及 $c$，将 $P + c$ 保存至字典表，并将前缀 $P$ 设为空，重复直到所有字符串编码完成。例如，图 11 邻接表的 LZ78 压缩结果如表 4 所示。LZ78 算法和 Repair 算法的区别在于压缩时，LZ78 算法的字典表以结果形式输出，查询节点信息的速度比 Repair 算法快，但每次解压需要从结果开始构造字典 $R$，只能压缩邻接表边表，限制了性能。 LZ78算法的压缩过程非常简单。在压缩时维护一个动态词典Dictionary，其包括了历史字符串的index与内容；压缩情况分为三种：\n若当前字符c未出现在词典中，则编码为(0, c)； 若当前字符c出现在词典中，则与词典做最长匹配，然后编码为(prefixIndex,lastChar)，其中，prefixIndex为最长匹配的前缀字符串，lastChar为最长匹配后的第一个字符； 为对最后一个字符的特殊处理，编码为(prefixIndex,)。 如果对于上述压缩的过程稍感费解，下面给出三个例子。例子一，对于字符串“ABBCBCABABCAABCAAB”压缩编码过程如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1. A is not in the Dictionary; insert it 2. B is not in the Dictionary; insert it 3. B is in the Dictionary. BC is not in the Dictionary; insert it. 4. B is in the Dictionary. BC is in the Dictionary. BCA is not in the Dictionary; insert it. 5. B is in the Dictionary. BA is not in the Dictionary; insert it. 6. B is in the Dictionary. BC is in the Dictionary. BCA is in the Dictionary. BCAA is not in the Dictionary; insert it. 7. B is in the Dictionary. BC is in the Dictionary. BCA is in the Dictionary. BCAA is in the Dictionary. BCAAB is not in the Dictionary; insert it. 5. 图数据压缩技术比较 文献(图数据表示与压缩技术综述) 采用来自米兰大学 LAW 的真实网页图数据集和社交网络数据集，对多种压缩技术进行对比。其中，表 5 展示了网页图数据集的相关属性，表 6 呈现了社交网络数据集的属性。通过一系列实验，该文献得出结论：k²-tree 的压缩率明显低于 Repair、LZ78 等算法，但能实现较好的时间 / 空间均衡。为凸显符号计算在大规模图数据压缩处理中的优势，本文又将 k²-tree 分别与 OBDD、k²-MDD 两种压缩技术进行实验对比，其结果分别记录在表 7 和表 8 中。\n在三种数据结构k²-tree、k²-MDD、OBDD中，使用一个位串T记录除最后一层节点的 0 值和 1 值，用一个位串L记录最后一层节点的 0 值和 1 值，T和L的总和为所需的存储空间。实验表明，采用OBDD压缩网页图时，T和L的总和约为k²-tree的 21%；采用k²-MDD压缩网页图时，T和L的总和约为k²-tree的 3%。在社交网络数据集enron、dblp1、dblp-2、dewiki上进行实验，得到的T和L的总和分别为k²-tree的 4.8%、5.1%、4.7%、3%，对存储空间的需求得到有效改善。\n实验方法 数据结构选择：选取k²-tree、k²-MDD、OBDD三种数据结构进行实验。 位串记录：使用位串T记录除最后一层节点的 0 值和 1 值，位串L记录最后一层节点的 0 值和 1 值。 数据集选择：使用社交网络数据集enron、dblp1、dblp-2、dewiki进行实验对比。 实验结果 网页图压缩：采用OBDD压缩网页图，T和L的总和约为k²-tree的 21%；采用k²-MDD压缩网页图，T和L的总和约为k²-tree的 3%。 社交网络数据集实验：在enron、dblp1、dblp-2、dewiki数据集上进行实验，得到的T和L的总和分别为k²-tree的 4.8%、5.1%、4.7%、3%。 结论 通过实验可以看出，使用k²-MDD和OBDD对网页图进行压缩以及在社交网络数据集上的实验，都有效地改善了存储空间的需求。\n","date":"2024-11-09T14:11:41+08:00","permalink":"https://SilentThink.github.io/p/%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%8E%8B%E7%BC%A9%E6%8A%80%E6%9C%AF%E7%BB%BC%E8%BF%B0/","title":"图数据压缩技术综述"},{"content":"Lab 3：interoperating in the world 1.介绍 到目前为止，在这门课程中，你已经以几乎完全符合标准的方式实现了传输控制协议。可以说，TCP 实现是世界上最受欢迎的单一计算机程序，存在于数十亿的设备中。大多数实现使用与你的不同的策略，但由于所有的 TCP 实现都共享一种共同的语言，它们都是可互操作的 —— 每个 TCP 实现都可以与任何其他实现成为对等方。这个检查点是关于在现实世界中测试你的 TCP 实现，并测量特定互联网路径的长期统计信息。\n如果你的 TCP 实现编写正确，你可能不需要为这个检查点编写任何代码。但是，尽管我们做出了努力，错误仍有可能逃过我们的单元测试。如果你发现问题，我们将欢迎你用 Wireshark 进行调试并修复任何错误。\n2. 准备开始 1 2 3 4 5 git fetch --all git merge origin/check4-startercode git merge upstream/check4-startercode cmake -S . -B build cmake --build build 3. 在现实世界中使用你实现的 TCP cmake --build build --target check webget\n","date":"2024-11-08T00:14:19+08:00","permalink":"https://SilentThink.github.io/p/cs144-lab-4/","title":"CS144 Lab 4"},{"content":"Lab 3：the TCP sender 0.介绍 在 Checkpoint 0 中，你实现了一个流量控制字节流（ByteStream）的抽象。在 Checkpoints 1 和 2 中，你实现了将不可靠数据报中携带的片段转换为传入字节流的工具：重组器（Reassembler）和 TCP 接收方（TCPReceiver）。\n现在，在 Checkpoint 3 中，你将实现连接的另一端。TCP 发送方（TCPSender）是一个将出站字节流转换为将成为不可靠数据报有效载荷的片段的工具。最后，在 Checkpoint 4 中，你将结合前几个实验的工作来创建一个有效的 TCP 实现：一个包含 TCP 发送方和 TCP 接收方的 TCP 对等方（TCPPeer）。你将使用这个与同学以及互联网上的真正服务器（采用TCP 协议的对等方）进行通信。\n1. Getting started 2. Checkpoint 3: The TCP Sender TCP 是一种协议，它通过不可靠的数据报可靠地传送一对流量控制的字节流（每个方向一个）。两个参与方参与 TCP 连接，并且每个参与方都是另一方的对等方。每个对等方同时充当 “发送方”（其自己的出站字节流）和 “接收方”（传入字节流）。\n本实验，你将实现 TCP 的 “发送方” 部分，负责从字节流（由某个发送方应用程序创建并写入）读取，并将该流转换为一系列传出的 TCP 段。在远程端，一个 TCP 接收方将这些段（那些到达的段 —— 它们可能并非全部都能到达）转换回原始字节流，并向发送方发送确认和窗口通告。\n你的 TCP 发送方的职责将是：\n跟踪接收方的窗口（接收带有确认号（ackno）和窗口大小的传入 TCP 接收方消息）。 在可能的情况下填充窗口，通过从字节流读取、创建新的 TCP 段（如果需要包括 SYN 和 FIN 标志）并发送它们。发送方应持续发送段，直到窗口已满或出站字节流没有更多内容可发送。 跟踪哪些段已发送但尚未被接收方确认 —— 我们称这些为 “未确认” 段。 如果自发送以来经过了足够长的时间并且它们尚未被确认，则重新发送未确认段。 2.1 TCP 发送方如何知道一个段是否丢失？ 你的 TCP 发送方将发送一堆 TCP 发送方消息。每个消息都将包含来自出站字节流的（可能为空）子字符串，用序列号进行索引以表明其在流中的位置，并在流的开头标记 SYN 标志，在结尾标记 FIN 标志。\n除了发送这些段之外，TCP 发送方还必须跟踪其未确认的段，直到它们所占用的序列号被完全确认。TCP 发送方的所有者会定期调用 TCP 发送方的tick方法，表示时间的流逝。TCP 发送方负责查看其未确认的 TCP 发送方消息集合，并确定最早发送的段在没有确认的情况下（即其所有序列号都未被确认）是否已经未确认了太长时间。如果是这样，它需要被重传（再次发送）。\n2.2 实现 TCP sender tcp_sender.hh\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 #pragma once #include \u0026#34;byte_stream.hh\u0026#34; #include \u0026#34;tcp_receiver_message.hh\u0026#34; #include \u0026#34;tcp_sender_message.hh\u0026#34; #include \u0026lt;cstdint\u0026gt; #include \u0026lt;functional\u0026gt; #include \u0026lt;queue\u0026gt; class TCPSender { public: /* Construct TCP sender with given default Retransmission Timeout and possible ISN */ TCPSender( ByteStream\u0026amp;\u0026amp; input, Wrap32 isn, uint64_t initial_RTO_ms ) : input_( std::move( input ) ), isn_( isn ), initial_RTO_ms_( initial_RTO_ms ), cur_RTO_ms_( initial_RTO_ms ) {} /* Generate an empty TCPSenderMessage */ TCPSenderMessage make_empty_message() const; /* Receive and process a TCPReceiverMessage from the peer\u0026#39;s receiver */ void receive( const TCPReceiverMessage\u0026amp; msg ); /* Type of the `transmit` function that the push and tick methods can use to send messages */ using TransmitFunction = std::function\u0026lt;void( const TCPSenderMessage\u0026amp; )\u0026gt;; /* Push bytes from the outbound stream */ void push( const TransmitFunction\u0026amp; transmit ); /* Time has passed by the given # of milliseconds since the last time the tick() method was called */ void tick( uint64_t ms_since_last_tick, const TransmitFunction\u0026amp; transmit ); // Accessors uint64_t sequence_numbers_in_flight() const; // How many sequence numbers are outstanding? uint64_t consecutive_retransmissions() const; // How many consecutive *re*transmissions have happened? Writer\u0026amp; writer() { return input_.writer(); } const Writer\u0026amp; writer() const { return input_.writer(); } // Access input stream reader, but const-only (can\u0026#39;t read from outside) const Reader\u0026amp; reader() const { return input_.reader(); } private: // Variables initialized in constructor ByteStream input_; Wrap32 isn_; uint64_t initial_RTO_ms_; uint64_t send_cnt_ {}; uint64_t ack_cnt_ {}; uint64_t retx_cnt_ {}; uint64_t wdsz_ = 1; bool is_syn_ {}; bool is_fin_ {}; // time uint64_t timer_ {}; bool is_timer_on_ {}; std::queue\u0026lt;TCPSenderMessage\u0026gt; retx_queue_ {}; uint64_t cur_RTO_ms_; }; tcp_sender.cc\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 #include \u0026#34;tcp_sender.hh\u0026#34; #include \u0026#34;byte_stream.hh\u0026#34; #include \u0026#34;tcp_config.hh\u0026#34; #include \u0026#34;tcp_sender_message.hh\u0026#34; #include \u0026#34;wrapping_integers.hh\u0026#34; #include \u0026lt;algorithm\u0026gt; using namespace std; uint64_t TCPSender::sequence_numbers_in_flight() const { return send_cnt_ - ack_cnt_; } uint64_t TCPSender::consecutive_retransmissions() const { return retx_cnt_; } void TCPSender::push( const TransmitFunction\u0026amp; transmit ) { while ((wdsz_ == 0 ? 1 : wdsz_) \u0026gt; sequence_numbers_in_flight()) { if (is_fin_) { break; } auto msg = make_empty_message(); if (!is_syn_) { msg.SYN = true; is_syn_ = true; } uint64_t remaining = (wdsz_ == 0 ? 1 : wdsz_) - sequence_numbers_in_flight(); uint64_t len = min(TCPConfig::MAX_PAYLOAD_SIZE, remaining - msg.sequence_length()); auto\u0026amp;\u0026amp; data = msg.payload; while (reader().bytes_buffered() \u0026amp;\u0026amp; data.size() \u0026lt; len) { auto cur_data = reader().peek(); cur_data = cur_data.substr(0, len - data.size()); data += cur_data; input_.reader().pop(data.size()); } if (!is_fin_ \u0026amp;\u0026amp; remaining \u0026gt; msg.sequence_length() \u0026amp;\u0026amp; reader().is_finished()) { msg.FIN = true; is_fin_ = true; } if (msg.sequence_length() == 0) { break; } transmit(msg); if (!is_timer_on_) { is_timer_on_ = true; timer_ = 0; } send_cnt_ += msg.sequence_length(); retx_queue_.emplace(msg); } } TCPSenderMessage TCPSender::make_empty_message() const { return { .seqno = Wrap32::wrap(send_cnt_, isn_), .SYN = false, .payload = {}, .FIN = false, .RST = input_.has_error() }; } void TCPSender::receive( const TCPReceiverMessage\u0026amp; msg ) { wdsz_ = msg.window_size; if (msg.RST) { input_.set_error(); return; } if (msg.ackno.has_value()) { const uint64_t recv_ackno = msg.ackno.value().unwrap(isn_, ack_cnt_); if (recv_ackno \u0026gt; send_cnt_) { return; } while (!retx_queue_.empty()) { auto retx_msg = retx_queue_.front(); if (recv_ackno \u0026lt; ack_cnt_ + retx_msg.sequence_length()) { break; } ack_cnt_ += retx_msg.sequence_length(); retx_queue_.pop(); retx_cnt_ = 0; cur_RTO_ms_ = initial_RTO_ms_; timer_ = 0; if (retx_queue_.empty()) { is_timer_on_ = false; } } } } void TCPSender::tick( uint64_t ms_since_last_tick, const TransmitFunction\u0026amp; transmit ) { if (is_timer_on_) { timer_ += ms_since_last_tick; } if (timer_ \u0026gt;= cur_RTO_ms_) { while (!retx_queue_.empty()) { auto msg = retx_queue_.front(); auto sendno = msg.seqno.unwrap(isn_, send_cnt_); if (sendno + msg.sequence_length() \u0026gt; ack_cnt_) { // if there are packets lost transmit(msg); if (wdsz_) { retx_cnt_ ++; cur_RTO_ms_ *= 2; } timer_ = 0; break; } else { retx_queue_.pop(); } } } } 测试cmake --build build --target check3：\n","date":"2024-11-07T23:56:33+08:00","permalink":"https://SilentThink.github.io/p/cs144-lab-3/","title":"CS144 Lab 3"},{"content":"Lab 2：the TCP receiver 0.介绍 在 Checkpoint 0 中，你实现了一个流量控制的字节流抽象（ByteStream）。在 Checkpoint 1 中，你创建了一个重组器（Reassembler），它接受来自同一字节流的一系列子字符串，并将它们重新组装回原始流。这些模块在你的 TCP 实现中会很有用，但它们中没有任何一个是特定于传输控制协议的细节的。现在情况发生了变化。在 Checkpoint 2 中，你将实现 TCP 接收方（TCPReceiver），这是 TCP 实现中处理传入字节流的部分。\nTCP 接收方从对等方的发送方接收消息（通过 receive () 方法），并将它们转换为对重组器的调用，重组器最终写入传入的字节流。应用程序从这个字节流中读取，就像你在实验 0 中通过从 TCPSocket 读取一样。\n同时，TCP 接收方还通过 send () 方法生成返回给对等方发送方的消息。这些 “接收方消息” 负责告诉发送方：\n“第一个未组装” 字节的索引，这被称为 “确认号”（acknowledgment number）或 “ackno”。这是接收方从发送方需要的第一个字节。 输出字节流中的可用容量。这被称为 “窗口大小”（window size）。 确认号和窗口大小一起描述了接收方的窗口：一个 TCP 发送方被允许发送的索引范围。通过使用窗口，接收方可以控制传入数据的流量，使发送方在接收方准备好接收更多数据之前限制其发送量。我们有时将确认号称为窗口的 “左边缘”（TCP 接收方想要的最小索引），将确认号加上窗口大小称为 “右边缘”（刚好超出 TCP 接收方想要的最大索引）。\n当你编写重组器和字节流时，你已经完成了实现 TCP 接收方所涉及的大部分算法工作；这个实验是关于将这些通用类连接到 TCP 的细节。最难的部分将涉及思考 TCP 如何表示每个字节在流中的位置 —— 称为 “序列号”。\n1. 准备开始 2. Checkpoint 2: The TCP Receiver 2.1 实现在 64 位索引和 32 位序列号之间进行转换 wrapping_integers.cc:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 #include \u0026#34;wrapping_integers.hh\u0026#34; using namespace std; Wrap32 Wrap32::wrap( uint64_t n, Wrap32 zero_point ) { return Wrap32 { static_cast\u0026lt;uint32_t\u0026gt;( ( static_cast\u0026lt;uint32_t\u0026gt;( n ) + zero_point.raw_value_ ) % ( 1UL \u0026lt;\u0026lt; 32 ) ) }; } uint64_t Wrap32::unwrap( Wrap32 zero_point, uint64_t checkpoint ) const { // Calculate the difference with 32-bit wraparound handling uint64_t diff = static_cast\u0026lt;uint64_t\u0026gt;( raw_value_ - zero_point.raw_value_ ); const uint64_t MODULO = 1UL \u0026lt;\u0026lt; 32; uint64_t remainder = checkpoint % MODULO; uint64_t quotient = checkpoint / MODULO; if ( diff + MODULO - remainder \u0026gt;= MODULO + ( MODULO \u0026gt;\u0026gt; 1 ) ) { if ( quotient \u0026gt; 0 ) diff = diff + ( quotient - 1 ) * MODULO; } else if ( diff + MODULO - remainder \u0026lt; MODULO - ( MODULO \u0026gt;\u0026gt; 1 ) ) { diff = diff + ( quotient + 1 ) * MODULO; } else diff = diff + quotient * MODULO; return diff; } 2.2 实现TCP receiver tcp_receriver.hh:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 #pragma once #include \u0026#34;reassembler.hh\u0026#34; #include \u0026#34;tcp_receiver_message.hh\u0026#34; #include \u0026#34;tcp_sender_message.hh\u0026#34; class TCPReceiver { public: // Construct with given Reassembler explicit TCPReceiver( Reassembler\u0026amp;\u0026amp; reassembler ) : reassembler_( std::move( reassembler ) ) {} /* * The TCPReceiver receives TCPSenderMessages, inserting their payload into the Reassembler * at the correct stream index. */ void receive( TCPSenderMessage message ); // The TCPReceiver sends TCPReceiverMessages to the peer\u0026#39;s TCPSender. TCPReceiverMessage send() const; // Access the output (only Reader is accessible non-const) const Reassembler\u0026amp; reassembler() const { return reassembler_; } Reader\u0026amp; reader() { return reassembler_.reader(); } const Reader\u0026amp; reader() const { return reassembler_.reader(); } const Writer\u0026amp; writer() const { return reassembler_.writer(); } private: Reassembler reassembler_; std::optional\u0026lt;Wrap32\u0026gt; isn_ {}; }; tcp_receiver.cc:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 #include \u0026#34;tcp_receiver.hh\u0026#34; using namespace std; void TCPReceiver::receive( TCPSenderMessage message ) { // Your code here. if ( writer().has_error() ) { return; } if ( message.RST ) { reader().set_error(); return; } // the parameters should be translated from seqno to absolute seqno if ( !isn_.has_value() ) { if ( !message.SYN ) { return; } isn_.emplace( message.seqno ); } Wrap32 zero_point = isn_.value(); uint64_t checkpoint = writer().bytes_pushed() + 1; Wrap32 sequo = message.seqno; if ( message.SYN ) { sequo = sequo + 1; } uint64_t abs_seqno = sequo.unwrap( zero_point, checkpoint ); uint64_t stream_index = abs_seqno - 1; reassembler_.insert( stream_index, move( message.payload ), message.FIN ); } TCPReceiverMessage TCPReceiver::send() const { uint16_t wdsz = static_cast\u0026lt;uint16_t\u0026gt;( min( writer().available_capacity(), static_cast\u0026lt;uint64_t\u0026gt;( UINT16_MAX ) ) ); bool reset = writer().has_error(); if ( isn_.has_value() ) { Wrap32 ackno = Wrap32::wrap( writer().bytes_pushed() + static_cast\u0026lt;uint64_t\u0026gt;( writer().is_closed() ), isn_.value() ) + 1; return { ackno, wdsz, reset }; } else { return { nullopt, wdsz, reset }; } } 测试结果cmake --build build --target check2：\n","date":"2024-11-07T23:39:07+08:00","permalink":"https://SilentThink.github.io/p/cs144-lab-2/","title":"CS144 Lab 2"},{"content":"Lab 1：stitching substrings into a byte stream 0. 概述 在 Checkpoint 0 中，你使用互联网流套接字从网站获取信息并发送电子邮件消息，使用的是 Linux 内置的传输控制协议（TCP）实现。这个 TCP 实现设法产生了一对可靠的有序字节流（一个从你到服务器，另一个相反），即使底层网络仅提供 “尽可能可靠” 的数据报。这里的意思是：可能会丢失、重新排序、更改或重复的短数据包。你还在一台计算机的内存中自己实现了字节流抽象。在接下来的实验中，你将自己实现 TCP，以便在由不可靠数据报网络分隔的一对计算机之间提供字节流抽象。\n还记得你在 Checkpoint 0 中刚刚实现的 ByteStream 吗？在接下来的实验中，你最终将在网络上传输两个这样的字节流：“outbound” ByteStream，用于本地应用程序写入套接字并且你的 TCP 将发送给对等方的数据；以及“inbound” ByteStream，用于来自对等方并将被本地应用程序读取的数据。\n1. 准备开始 你的 TCP 实现将使用与在 Checkpoint 0 中相同的 Minnow 库，同时还有额外的类和测试。要开始进行：\n确保你已经将 Checkpoint 0 的所有解决方案都提交了。请不要修改 src 目录或 webget.cc 之外的任何文件。否则，在合并 Checkpoint 1 的起始代码时可能会遇到问题。 在实验作业的存储库中，运行 git fetch 以获取实验作业的最新版本。 通过运行 git merge origin/check1-startercode 下载 Checkpoint 1 的起始代码。（如果你将 “origin” 远程仓库重命名为其他名称，你可能需要在这里使用不同的名称，例如 git merge upstream/check1-startercode。） 确保你的构建系统已正确设置：cmake -S. -B build。 编译源代码：cmake --build build。 2. 将子字符串按顺序排列 作为实验作业的一部分，你将实现一个 TCP 接收方：这个模块接收数据报并将它们转换为可靠的字节流，以便应用程序从套接字中读取 —— 就像你的 webget 程序在 Checkpoint 0 中从网络服务器读取字节流一样。\nTCP 发送方将其字节流分割成短的片段（每个子字符串不超过约 1460 字节），以便它们都能装在一个数据报中。但是网络可能会重新排序这些数据报，或者丢弃它们，或者多次传递它们。接收方必须将这些片段重新组装成它们最初的连续字节流。\n在这个实验中，你将编写负责这种重新组装的数据结构：一个重组器（Reassembler）。它将接收子字符串，由一串字节组成，以及该字符串在较大字节流中的第一个字节的索引。字节流中的每个字节都有自己唯一的索引，从零开始向上计数。一旦重组器知道了字节流中的下一个字节，它就会将其写入到一个字节流（ByteStream）的写入端 —— 这与你在 Checkpoint 0 中实现的字节流是同一个。重组器的 “客户” 可以从同一个字节流的读取端进行读取。\n以下是这个接口的样子：\n1 2 3 4 5 6 // 插入一个新的子字符串以重新组装到字节流中。 void insert(uint64_t first_index, std::string data, bool is_last_substring); // 重组器自身存储了多少字节？ uint64_t bytes_pending() const; // 访问输出流的读取器 Reader\u0026amp; reader(); ⋆为什么要这样做呢？\nTCP 对重新排序和重复的鲁棒性来自于它能够将字节流的任意片段重新拼接回原始流的能力。在一个独立的可测试模块中实现这一点将使处理传入的片段更加容易。\n重组器的完整（公共）接口由 “reassembler.hh” 头文件中的 “Reassembler” 类描述。你的任务是实现这个类。你可以向 “Reassembler” 类添加任何你想要的私有成员和成员函数，但你不能改变它的公共接口。\n2.1 重组器在内部应该存储什么？ insert方法向重组器告知字节流的一个新片段，以及它在整个流中的位置（子字符串开头的索引）。\n原则上，重组器必须处理三类信息：\n是流中的下一个字节。一旦知道这些字节，重组器应立即将它们推送到流中（输出的 .writer()）。 适合流的可用容量但由于前面的字节仍未知而不能写入的字节。这些应该在重组器内部存储。 超出流的可用容量的字节。这些应该被丢弃。重组器不会存储任何不能立即推送到字节流中，或者一旦前面的字节变得已知也不能推送到字节流中的字节。 这种行为的目标是限制重组器和字节流使用的内存量，无论传入的子字符串如何到达。我们在下面的图片中进行了说明。“容量” 是两者的上限：\n在重组后的字节流中缓冲的字节数（显示为绿色），以及 可以由 “未组装” 的子字符串使用的字节数（显示为红色）。 reassembler.hh:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 #pragma once #include \u0026#34;byte_stream.hh\u0026#34; #include \u0026lt;set\u0026gt; #include \u0026lt;vector\u0026gt; struct Interval { uint64_t start; uint64_t end; std::string data; bool operator\u0026lt;(const Interval\u0026amp; other) const { if (start == other.start) { return end \u0026lt; other.end; } return start \u0026lt; other.start; } }; class Reassembler { public: // Construct Reassembler to write into given ByteStream. explicit Reassembler( ByteStream\u0026amp;\u0026amp; output ) : output_( std::move( output ) ) {} /* * Insert a new substring to be reassembled into a ByteStream. * `first_index`: the index of the first byte of the substring * `data`: the substring itself * `is_last_substring`: this substring represents the end of the stream * `output`: a mutable reference to the Writer * * The Reassembler\u0026#39;s job is to reassemble the indexed substrings (possibly out-of-order * and possibly overlapping) back into the original ByteStream. As soon as the Reassembler * learns the next byte in the stream, it should write it to the output. * * If the Reassembler learns about bytes that fit within the stream\u0026#39;s available capacity * but can\u0026#39;t yet be written (because earlier bytes remain unknown), it should store them * internally until the gaps are filled in. * * The Reassembler should discard any bytes that lie beyond the stream\u0026#39;s available capacity * (i.e., bytes that couldn\u0026#39;t be written even if earlier gaps get filled in). * * The Reassembler should close the stream after writing the last byte. */ void insert( uint64_t first_index, std::string data, bool is_last_substring ); // How many bytes are stored in the Reassembler itself? uint64_t bytes_pending() const; // Access output stream reader Reader\u0026amp; reader() { return output_.reader(); } const Reader\u0026amp; reader() const { return output_.reader(); } // Access output stream writer, but const-only (can\u0026#39;t write from outside) const Writer\u0026amp; writer() const { return output_.writer(); } private: ByteStream output_; // the Reassembler writes to this ByteStream std::set\u0026lt;Interval\u0026gt; buf_{}; uint64_t nxt_expected_idx_ = 0; uint64_t eof_idx_ = UINT64_MAX; }; reassembler.cc\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 #include \u0026#34;reassembler.hh\u0026#34; using namespace std; void Reassembler::insert( uint64_t first_index, string data, bool is_last_substring ) { uint64_t wd_start = nxt_expected_idx_; uint64_t wd_end = wd_start + output_.writer().available_capacity(); uint64_t cur_start = first_index; uint64_t cur_end = cur_start + data.size(); // set the eof index of this reassembling if (is_last_substring) { eof_idx_ = cur_end; } if (cur_start \u0026gt;= wd_end) { if (nxt_expected_idx_ == eof_idx_) { output_.writer().close(); } return; } uint64_t start_idx = max(wd_start, cur_start); uint64_t end_idx = min(wd_end, cur_end); if (start_idx \u0026gt;= end_idx) { if (nxt_expected_idx_ == eof_idx_) { output_.writer().close(); } return; } uint64_t len = end_idx - start_idx; // insert the current data buf_.insert({start_idx, end_idx, data.substr(start_idx - first_index, len)}); // handle the overlapping of intervals std::vector\u0026lt;Interval\u0026gt; merged; auto it = buf_.begin(); Interval last = *it; it ++; while (it != buf_.end()) { if (it-\u0026gt;start \u0026lt;= last.end) { if (last.end \u0026lt; it-\u0026gt;end) { last.end = it-\u0026gt;end; last.data = last.data.substr(0, it-\u0026gt;start - last.start) + it-\u0026gt;data; } } else { merged.push_back(last); last = *it; } it ++; } merged.push_back(last); buf_.clear(); for (const auto\u0026amp; interval : merged) { buf_.insert(interval); } // push when it ready it = buf_.begin(); while (it-\u0026gt;start == nxt_expected_idx_) { output_.writer().push(it-\u0026gt;data); nxt_expected_idx_ = it-\u0026gt;end; it = buf_.erase(it); } // close when all bytes are pushed if (nxt_expected_idx_ == eof_idx_) { output_.writer().close(); } } uint64_t Reassembler::bytes_pending() const { uint64_t pendcnt = 0; for (const auto\u0026amp; interval : buf_) { pendcnt += interval.end - interval.start; } return pendcnt; } 3. 开发和调试建议 你可以使用cmake --build build --target check1（在编译代码后）来测试你的代码。 请重新阅读实验 0 文档中的 “使用 Git” 部分，并记住将代码保存在分发时所在的 Git 仓库的主分支上。进行小的提交，使用良好的提交消息来标识更改了什么以及为什么更改。 请努力使你的代码对为其进行风格和正确性评分的课程助理来说是可读的。为变量使用合理和清晰的命名约定。使用注释来解释复杂或微妙的代码部分。使用 “防御性编程”—— 显式检查函数的前置条件或不变量，如果有任何错误则抛出异常。在你的设计中使用模块化 —— 识别常见的抽象和行为，并在可能的情况下将它们提取出来。重复的代码块和巨大的函数会使你的代码难以理解。 也请保持在 Checkpoint 0 文档中描述的 “现代 C++” 风格。cppreference 网站（https://en.cppreference.com）是一个很好的资源，尽管你在做这些实验时不需要 C++ 的任何复杂特性。（有时你可能需要使用move()函数来传递一个不能被复制的对象。） 如果你在构建时遇到问题并且不确定如何修复，可以删除你的构建目录（rm -rf build—— 请小心不要输入错误，因为这将删除你指定的任何内容），然后再次运行cmake -S. -B build。 check1测试结果：\n","date":"2024-11-07T22:50:09+08:00","permalink":"https://SilentThink.github.io/p/cs144-lab-1/","title":"CS144 Lab 1"},{"content":" Lab 0：networking warmup 0.介绍 本次热身任务中，你需要在自己的计算机上安装 Linux 系统，学习如何手动通过互联网执行一些任务，用 C++ 编写一个小程序从互联网上获取网页，并在内存中实现网络的一个关键抽象概念：在写入者和读取者之间的可靠字节流。\n1. GNU/Linux环境配置 windows: 我使用的环境为Ubuntu 22.04 @ WSL2\n运行以下命令安装需要的包\n1 2 sudo apt update \u0026amp;\u0026amp; sudo apt install git cmake gdb build-essential clang \\ clang-tidy clang-format gcc-doc pkg-config glibc-doc tcpdump tshark 项目编译运行及调试需要的g++ 版本:13及以上\nMac OS: 官方文档中的建议：\nIf you have a 2020–24 MacBook (with the ARM64 M1/M2/M3 chips), VirtualBox will\nnot successfully run. Instead, please install the UTM virtual machine software and our\nARM64 virtual machine image from https://stanford.edu/class/cs144/vm_howto/ .\n我的配置方法——docker:\ndockerfile:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 FROM ubuntu:latest WORKDIR /usr/src/app RUN apt-get update \u0026amp;\u0026amp; apt-get install -y \\ build-essential \\ g++-13 \\ clang-15 RUN update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-13 100 \\ \u0026amp;\u0026amp; update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-13 100 \\ \u0026amp;\u0026amp; update-alternatives --install /usr/bin/clang clang /usr/bin/clang-15 100 ENV CC=gcc ENV CXX=g++ RUN apt-get clean \u0026amp;\u0026amp; rm -rf /var/lib/apt/lists/* CMD [ \u0026#34;/bin/bash\u0026#34;] 2. 手动完成网络任务 在 “Networking by hand” 部分，你需要手动完成两项任务：检索网页（就像网络浏览器一样）和发送电子邮件消息（就像电子邮件客户端一样）。这两项任务都依赖于一种称为可靠双向字节流的网络抽象概念。你将在终端中输入一系列字节，相同顺序的字节序列最终将被传递到另一台计算机（服务器）上运行的程序。服务器用它自己的字节序列进行响应，并将其传递回你的终端。\n2.1 获取一个网页 打开浏览器访问 http://cs144.keithw.org/hello 并观察结果 在linux终端中执行和浏览器一样的工作 ​\t(a) 运行 telnet cs144.keithw.org http\n这会告诉 telnet 程序在你的计算机和另一台名为 “cs144.keithw.org” 的计算机之间打开一个可靠的字节流，并且在那台计算机上运行特定的服务：用于万维网的超文本传输协议（“http” 服务）。如果你的计算机已正确设置并连接到互联网，你将看到如上图相应的输出。\n如果你想要退出这个连接，按住键盘的 ctrl 键然后按 ]，之后敲下回车键 Enter 即可 (b) 输入 GET /hello HTTP/1.1，这告诉服务器 URL 的路径部分（从第三个斜杠开始的部分）。\n​\t(c) 输入 Host: cs144.keithw.org，这告诉服务器 URL 的主机部分（在 “http://” 和第三个斜杠之间的部分）。\n​\t(d) 输入 Connection: close，这告诉服务器你已完成请求，并且它应在回复完成后尽快关闭连接。\n​\t(e) 再按一次回车键，这发送一个空行并告诉服务器你已完成 HTTP 请求。\n​\t(f) 如果一切顺利，你将看到与浏览器看到的相同响应，前面是 HTTP 头，它告诉浏览器如何解释响应。\n2.2 给自己发邮件 略：没有斯坦福的邮箱，无法完成这个任务\n2.3 监听与连接 你已经看到了用 telnet 能做什么：它是一个客户端程序，可以与其他计算机上运行的程序建立外出连接。现在是时候尝试运行一个简单的服务器了：即等待客户端连接它的程序。\n在一个终端窗口中，在你的虚拟机上运行 netcat -v -l -p 9090。\n让 netcat 保持运行状态。在另一个终端窗口中，运行 telnet localhost 9090。\n如果一切顺利，netcat 将会打印出类似 “Connection from localhost 53500 received! ” 的内容。\n现在尝试在任意一个终端窗口中输入内容 —— 无论是 netcat（服务器）窗口还是 telnet（客户端）窗口。注意，你在一个窗口中输入的任何内容都会出现在另一个窗口中，反之亦然。你必须按回车键才能传输字节。\n在 netcat 窗口中，通过输入 ctrl-C 退出程序。注意，telnet 程序也会立即退出。\n3. 使用操作系统流套接字编写网络程序 在本次热身实验的下一部分，你要编写一个简短程序从互联网获取网页。这会利用 Linux 内核及大多数其他操作系统提供的功能，即在两个程序间创建可靠双向字节流，比如一个程序在你的计算机上运行，另一个在互联网上的其他计算机（如 Web 服务器或 netcat 程序）上运行。此功能称为流套接字，对于程序和 Web 服务器来说，它就像普通文件描述符。\n但实际上，互联网并不直接提供可靠字节流服务，只是尽最大努力传送数据报，而数据报可能丢失、乱序、内容改变甚至被复制多次。连接两端的操作系统通常负责将 “尽力而为的数据报” 转换为 “可靠字节流”，这是通过 1981 年的传输控制协议（TCP）实现的。\n在本次实验中，你将借助操作系统对 TCP 的支持编写 “webget” 程序，创建 TCP 流套接字连接 Web 服务器获取页面。未来的实验中，你将自己实现传输控制协议，从不太可靠的数据报中创建可靠字节流。\n3.1 获取并部署原始代码 运行 git clone https://github.com/cs144/minnow 拉取代码 将项目部署到自己的github仓库 进入 Lab 0 的目录：cd minnow 创建build目录来编译程序： cmake -S . -B build 编译源代码：cmake --build build 查看是否安装g++13版本，对应的路径在哪：\n配置默认编译器：nano ~/.bashrc，在文件末尾添加以下两行代码：\n1 2 export CC=gcc-13 export CXX=g++-13 ctrl+x,Enter 进行保存\n运行source ~/.bashrc进行更新\n创建build目录\n编译\n3.2 现代C++编码规范 参考：\nhttp://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines\nhttps://en.cppreference.com\n具体请看源文档：check0.pdf\n在push到github之前，运行 cmake --build build --target tidy 以获取有关如何改进与 C++ 编程实践相关的代码的建议，并运行 cmake --build build --target format 以一致地格式化代码。\n使用git:\nPlease make frequent small commits as you work, and use commit messages that identify what changed and why\n参考：\nhttps://guides.github.com/introduction/git-handbook\n3.3 阅读 Minnow 提供的源代码框架 请仔细阅读公共接口（在文件 util/socket.hh 和 util/file_descriptor.hh 中 “public:” 之后的部分。请注意，Socket 是一种 FileDescriptor 类型，而 TCPSocket 是一种 Socket 类型）。\n3.4 编写 webget 现在是时候实现 “webget” 了，这是一个使用操作系统的 TCP 支持和流套接字抽象从互联网上获取网页的程序 —— 就像你在本次实验的早些时候手动所做的那样。\n从构建目录中，在文本编辑器或集成开发环境（IDE）中打开 “../apps/webget.cc” 文件。 在 “get_URL” 函数中实现简单的 Web 客户端。 按照文件中的描述，使用之前用过的 HTTP（Web）请求格式。同时要使用 “TCPSocket” 和 “Address” 类。 明确了实现的具体位置和所需的类。 提示： 在 HTTP 中，每行必须以 “\\r\\n” 结尾，不能仅用 “\\n” 或 “endl”。强调了 HTTP 协议的格式要求。 客户端请求中要包含 “Connection: close”，告知服务器在本次请求后不再等待更多请求，服务器发送一个回复后就结束传出字节流。当套接字到达 “EOF” 时，表明传入字节流结束，客户端由此知道服务器已完成回复。详细说明了与服务器交互的关键设置。 确保读取并打印服务器的所有输出直到套接字到达 “EOF”，单次调用 “read” 是不够的。强调了要完整处理服务器的响应。 预计需要写大约十行代码，给出了代码量的大致预期。 通过运行 make 编译程序。\n测试程序。\n运行 ./apps/webget cs144.keithw.org /hello 进行测试。 比较与在浏览器中访问 “http://cs144.keithw.org/hello” 的结果以及与 2.1 节结果的差异。鼓励用任何 http URL 进行实验。 自动化测试： 当程序看似正常工作时，运行 “cmake --build build --target check webget” 进行自动化测试。 在实现 “get_URL” 函数之前，会看到特定的测试结果，包括编译检查通过但功能测试失败，并给出警告和错误信息。完成作业后，测试应全部通过。 webget.cc:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 #include \u0026#34;socket.hh\u0026#34; #include \u0026#34;tcp_minnow_socket.hh\u0026#34; #include \u0026lt;cstdlib\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;span\u0026gt; #include \u0026lt;string\u0026gt; using namespace std; void get_URL( const string\u0026amp; host, const string\u0026amp; path ) { CS144TCPSocket sock {}; sock.connect( Address( host, \u0026#34;http\u0026#34; ) ); sock.write( \u0026#34;GET \u0026#34; + path + \u0026#34; HTTP/1.1\\r\\nHost: \u0026#34; + host + \u0026#34;\\r\\nConnection: close\\r\\n\\r\\n\u0026#34; ); sock.shutdown( SHUT_WR ); while ( !sock.eof() ) { string recvd; sock.read( recvd ); cout \u0026lt;\u0026lt; recvd; } sock.close(); return; } int main( int argc, char* argv[] ) { try { if ( argc \u0026lt;= 0 ) { abort(); // For sticklers: don\u0026#39;t try to access argv[0] if argc \u0026lt;= 0. } auto args = span( argv, argc ); // The program takes two command-line arguments: the hostname and \u0026#34;path\u0026#34; part of the URL. // Print the usage message unless there are these two arguments (plus the program name // itself, so arg count = 3 in total). if ( argc != 3 ) { cerr \u0026lt;\u0026lt; \u0026#34;Usage: \u0026#34; \u0026lt;\u0026lt; args.front() \u0026lt;\u0026lt; \u0026#34; HOST PATH\\n\u0026#34;; cerr \u0026lt;\u0026lt; \u0026#34;\\tExample: \u0026#34; \u0026lt;\u0026lt; args.front() \u0026lt;\u0026lt; \u0026#34; stanford.edu /class/cs144\\n\u0026#34;; return EXIT_FAILURE; } // Get the command-line arguments. const string host { args[1] }; const string path { args[2] }; // Call the student-written function. get_URL( host, path ); } catch ( const exception\u0026amp; e ) { cerr \u0026lt;\u0026lt; e.what() \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; return EXIT_FAILURE; } return EXIT_SUCCESS; } 进入build目录执行make\n运行./apps/webget cs144.keithw.org /hello：\n回到minnow目录运行 cmake --build build --target check webget：\n3.5 实现内存中的可靠字节流（ByteStream） 你将在一台计算机的内存中实现一个提供这种抽象的对象。字节在 “输入” 侧被写入，并可以从 “输出” 侧以相同的顺序被读取。这个字节流是有限的：写入者可以结束输入，之后就不能再写入更多字节。当读取者读到流的末尾时，它将到达 “EOF”（文件结束），并且不能再读取更多字节。\n你的字节流也将进行流量控制，以在任何给定时间限制其内存消耗。该对象在初始化时带有特定的 “容量”：即在任何给定时刻它愿意在自己的内存中存储的最大字节数。字节流将限制写入者在任何给定时刻可以写入的量，以确保流不会超过其存储容量。当读取者读取字节并从流中排出它们时，写入者被允许写入更多。你的字节流用于单个线程中 —— 你不必担心并发的写入者 / 读取者、锁定或竞争条件。\n需要明确的是：字节流是有限的，但在写入者结束输入并完成流之前，它可以几乎是任意长的。你的实现必须能够处理比容量长得多的流。容量限制了在给定时刻内存中（已写入但尚未读取）的字节数，但不限制流的长度。一个容量只有一个字节的对象仍然可以承载一个长达数 TB 的流，只要写入者一次写入一个字节，并且在写入者被允许写入下一个字节之前，读取者读取每个字节。\nwriter的接口如下:\n1 2 3 4 5 6 7 void push( std::string data ); // Push data to stream, but only as much as available capacity allows. void close(); // Signal that the stream has reached its ending. Nothing more will be written.* bool is_closed() const; // Has the stream been closed? uint64_t available_capacity() const; // How many bytes can be pushed to the stream right now? uint64_t bytes_pushed() const; // Total number of bytes cumulatively pushed to the stream reader的接口如下:\n1 2 3 4 5 6 std::string_view peek() const; // Peek at the next bytes in the buffer void pop( uint64_t len ); // Remove `len` bytes from the buffer bool is_finished() const; // Is the stream finished (closed and fully popped)? bool has_error() const; // Has the stream had an error? uint64_t bytes_buffered() const; // Number of bytes currently buffered (pushed and not popped) uint64_t bytes_popped() const; // Total number of bytes cumulatively popped from stream 请打开 “src/byte_stream.hh” 和 “src/byte_stream.cc” 文件，并实现一个提供此接口的对象。在开发字节流实现的过程中，你可以使用 “cmake --build build --target check0” 运行自动化测试。如果所有测试通过，check0 测试将运行你的实现的速度基准测试。对于本课程而言，任何速度快于 0.1 Gbit/s（换句话说，每秒 1 亿比特）的都是可以接受的。（一个实现有可能执行速度快于 10 Gbit/s，但这取决于你的计算机速度，不是必需的。）\nbyte_stream.hh:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 #pragma once #include \u0026lt;cstdint\u0026gt; #include \u0026lt;deque\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;string_view\u0026gt; class Reader; class Writer; class ByteStream { public: explicit ByteStream( uint64_t capacity ); // Helper functions (provided) to access the ByteStream\u0026#39;s Reader and Writer interfaces Reader\u0026amp; reader(); const Reader\u0026amp; reader() const; Writer\u0026amp; writer(); const Writer\u0026amp; writer() const; void set_error() { error_ = true; }; // Signal that the stream suffered an error. bool has_error() const { return error_; }; // Has the stream had an error? protected: // Please add any additional state to the ByteStream here, and not to the Writer and Reader interfaces. uint64_t capacity_; bool error_ {}; std::deque\u0026lt;std::string\u0026gt; buffer_ {}; bool is_closed_ {}; uint64_t pushcnt_ {}; uint64_t popcnt_ {}; uint64_t buffer_bytes_size_ {}; }; class Writer : public ByteStream { public: void push( std::string data ); // Push data to stream, but only as much as available capacity allows. void close(); // Signal that the stream has reached its ending. Nothing more will be written. bool is_closed() const; // Has the stream been closed? uint64_t available_capacity() const; // How many bytes can be pushed to the stream right now? uint64_t bytes_pushed() const; // Total number of bytes cumulatively pushed to the stream }; class Reader : public ByteStream { public: std::string_view peek() const; // Peek at the next bytes in the buffer void pop( uint64_t len ); // Remove `len` bytes from the buffer bool is_finished() const; // Is the stream finished (closed and fully popped)? uint64_t bytes_buffered() const; // Number of bytes currently buffered (pushed and not popped) uint64_t bytes_popped() const; // Total number of bytes cumulatively popped from stream }; /* * read: A (provided) helper function thats peeks and pops up to `len` bytes * from a ByteStream Reader into a string; */ void read( Reader\u0026amp; reader, uint64_t len, std::string\u0026amp; out ); byte_stream.cc:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 #include \u0026#34;byte_stream.hh\u0026#34; using namespace std; ByteStream::ByteStream( uint64_t capacity ) : capacity_( capacity ) {} bool Writer::is_closed() const { // Your code here. return is_closed_; } void Writer::push( string data ) { // Your code here. if ( is_closed_ || available_capacity() == 0 || data.empty() ) { return; } uint64_t const push_size = std::min( data.size(), available_capacity() ); if ( push_size \u0026lt; data.size() ) { data = data.substr( 0, push_size ); } buffer_.push_back( std::move( data ) ); buffer_bytes_size_ += push_size; pushcnt_ += push_size; return; } void Writer::close() { // Your code here. is_closed_ = true; } uint64_t Writer::available_capacity() const { // Your code here. return ( capacity_ - buffer_bytes_size_ ); } uint64_t Writer::bytes_pushed() const { // Your code here. return pushcnt_; } bool Reader::is_finished() const { // Your code here. return ( is_closed_ \u0026amp;\u0026amp; pushcnt_ == popcnt_ ); } uint64_t Reader::bytes_popped() const { // Your code here. return popcnt_; } string_view Reader::peek() const { // Your code here. if ( buffer_.empty() ) { return {}; } return std::string_view( buffer_.front() ); } void Reader::pop( uint64_t len ) { // Your code here. uint64_t pop_size = std::min( len, buffer_bytes_size_ ); buffer_bytes_size_ -= pop_size; popcnt_ += pop_size; while ( pop_size \u0026gt; 0 ) { uint64_t const to_pop_size = buffer_.front().size(); if ( to_pop_size \u0026lt;= pop_size ) { buffer_.pop_front(); pop_size -= to_pop_size; } else { buffer_.front().erase( 0, pop_size ); pop_size = 0; } } return; } uint64_t Reader::bytes_buffered() const { // Your code here. return pushcnt_ - popcnt_; } 执行自动化测试cmake --build build --target check0：\nCheck0 Over !! ","date":"2024-11-07T13:59:07+08:00","permalink":"https://SilentThink.github.io/p/cs144-lab-0/","title":"CS144 Lab 0"},{"content":"Title:hello world 1 .\\hugo.exe new site dev 1 ./hugo server -D 1 .\\hugo.exe new content post/myFirstBlog/index.md ","date":"2024-11-07T13:59:07+08:00","permalink":"https://SilentThink.github.io/p/myfirstblog/","title":"MyFirstBlog"},{"content":"正文测试 而这些并不是完全重要，更加重要的问题是， 带着这些问题，我们来审视一下学生会退会。 既然如何， 对我个人而言，学生会退会不仅仅是一个重大的事件，还可能会改变我的人生。 我们不得不面对一个非常尴尬的事实，那就是， 可是，即使是这样，学生会退会的出现仍然代表了一定的意义。 学生会退会，发生了会如何，不发生又会如何。 经过上述讨论， 生活中，若学生会退会出现了，我们就不得不考虑它出现了的事实。 学生会退会，到底应该如何实现。 这样看来， 在这种困难的抉择下，本人思来想去，寝食难安。 对我个人而言，学生会退会不仅仅是一个重大的事件，还可能会改变我的人生。 就我个人来说，学生会退会对我的意义，不能不说非常重大。 莎士比亚曾经提到过，人的一生是短的，但如果卑劣地过这一生，就太长了。这似乎解答了我的疑惑。 莫扎特说过一句富有哲理的话，谁和我一样用功，谁就会和我一样成功。这启发了我， 对我个人而言，学生会退会不仅仅是一个重大的事件，还可能会改变我的人生。 学生会退会，到底应该如何实现。 一般来说， 从这个角度来看， 这种事实对本人来说意义重大，相信对这个世界也是有一定意义的。 在这种困难的抉择下，本人思来想去，寝食难安。 了解清楚学生会退会到底是一种怎么样的存在，是解决一切问题的关键。 一般来说， 生活中，若学生会退会出现了，我们就不得不考虑它出现了的事实。 问题的关键究竟为何？ 而这些并不是完全重要，更加重要的问题是。\n奥斯特洛夫斯基曾经说过，共同的事业，共同的斗争，可以使人们产生忍受一切的力量。　带着这句话，我们还要更加慎重的审视这个问题： 一般来讲，我们都必须务必慎重的考虑考虑。 既然如此， 这种事实对本人来说意义重大，相信对这个世界也是有一定意义的。 带着这些问题，我们来审视一下学生会退会。 我认为， 我认为， 在这种困难的抉择下，本人思来想去，寝食难安。 问题的关键究竟为何？ 每个人都不得不面对这些问题。 在面对这种问题时， 要想清楚，学生会退会，到底是一种怎么样的存在。 我认为， 既然如此， 每个人都不得不面对这些问题。 在面对这种问题时， 那么， 我认为， 学生会退会因何而发生。\n引用 思念是最暖的忧伤像一双翅膀\n让我停不了飞不远在过往游荡\n不告而别的你 就算为了我着想\n这么沉痛的呵护 我怎么能翱翔\n最暖的憂傷 - 田馥甄\n图片 1 2 3 ![Photo by Florian Klauer on Unsplash](florian-klauer-nptLmg6jqDo-unsplash.jpg) ![Photo by Luca Bravo on Unsplash](luca-bravo-alS7ewQ41M8-unsplash.jpg) ![Photo by Helena Hertz on Unsplash](helena-hertz-wWZzXlDpMog-unsplash.jpg) ![Photo by Hudai Gayiran on Unsplash](hudai-gayiran-3Od_VKcDEAA-unsplash.jpg) 相册语法来自 Typlog\n","date":"2020-09-09T00:00:00Z","image":"https://SilentThink.github.io/p/test-chinese/helena-hertz-wWZzXlDpMog-unsplash_hu4699868770670889127.jpg","permalink":"https://SilentThink.github.io/p/test-chinese/","title":"Chinese Test"},{"content":"This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.\nHeadings The following HTML \u0026lt;h1\u0026gt;—\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1 H2 H3 H4 H5 H6 Paragraph Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\nBlockquotes The blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations.\nBlockquote without attribution Tiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote.\nBlockquote with attribution Don\u0026rsquo;t communicate by sharing memory, share memory by communicating.\n— Rob Pike1\nTables Tables aren\u0026rsquo;t part of the core Markdown spec, but Hugo supports supports them out-of-the-box.\nName Age Bob 27 Alice 23 Inline Markdown within tables Italics Bold Code italics bold code A B C D E F Lorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus ultricies, sapien non euismod aliquam, dui ligula tincidunt odio, at accumsan nulla sapien eget ex. Proin eleifend dictum ipsum, non euismod ipsum pulvinar et. Vivamus sollicitudin, quam in pulvinar aliquam, metus elit pretium purus Proin sit amet velit nec enim imperdiet vehicula. Ut bibendum vestibulum quam, eu egestas turpis gravida nec Sed scelerisque nec turpis vel viverra. Vivamus vitae pretium sapien Code Blocks Code block with backticks 1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block indented with four spaces \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block with Hugo\u0026rsquo;s internal highlight shortcode 1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Diff code block 1 2 3 4 5 [dependencies.bevy] git = \u0026#34;https://github.com/bevyengine/bevy\u0026#34; rev = \u0026#34;11f52b8c72fc3a568e8bb4a4cd1f3eb025ac2e13\u0026#34; - features = [\u0026#34;dynamic\u0026#34;] + features = [\u0026#34;jpeg\u0026#34;, \u0026#34;dynamic\u0026#34;] List Types Ordered List First item Second item Third item Unordered List List item Another item And another item Nested list Fruit Apple Orange Banana Dairy Milk Cheese Other Elements — abbr, sub, sup, kbd, mark GIF is a bitmap image format.\nH2O\nXn + Yn = Zn\nPress CTRL + ALT + Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\nHyperlinked image The above quote is excerpted from Rob Pike\u0026rsquo;s talk during Gopherfest, November 18, 2015.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2019-03-11T00:00:00Z","image":"https://SilentThink.github.io/p/markdown-syntax-guide/pawel-czerwinski-8uZPynIu-rQ-unsplash_hu6307248181568134095.jpg","permalink":"https://SilentThink.github.io/p/markdown-syntax-guide/","title":"Markdown Syntax Guide"},{"content":"Lorem est tota propiore conpellat pectoribus de pectora summo.\nRedit teque digerit hominumque toris verebor lumina non cervice subde tollit usus habet Arctonque, furores quas nec ferunt. Quoque montibus nunc caluere tempus inhospita parcite confusaque translucet patri vestro qui optatis lumine cognoscere flos nubis! Fronde ipsamque patulos Dryopen deorum.\nExierant elisi ambit vivere dedere Duce pollice Eris modo Spargitque ferrea quos palude Rursus nulli murmur; hastile inridet ut ab gravi sententia! Nomine potitus silentia flumen, sustinet placuit petis in dilapsa erat sunt. Atria tractus malis.\nComas hunc haec pietate fetum procerum dixit Post torum vates letum Tiresia Flumen querellas Arcanaque montibus omnes Quidem et Vagus elidunt The Van de Graaf Canon\nMane refeci capiebant unda mulcebat Victa caducifer, malo vulnere contra dicere aurato, ludit regale, voca! Retorsit colit est profanae esse virescere furit nec; iaculi matertera et visa est, viribus. Divesque creatis, tecta novat collumque vulnus est, parvas. Faces illo pepulere tempus adest. Tendit flamma, ab opes virum sustinet, sidus sequendo urbis.\nIubar proles corpore raptos vero auctor imperium; sed et huic: manus caeli Lelegas tu lux. Verbis obstitit intus oblectamina fixis linguisque ausus sperare Echionides cornuaque tenent clausit possit. Omnia putatur. Praeteritae refert ausus; ferebant e primus lora nutat, vici quae mea ipse. Et iter nil spectatae vulnus haerentia iuste et exercebat, sui et.\nEurytus Hector, materna ipsumque ut Politen, nec, nate, ignari, vernum cohaesit sequitur. Vel mitis temploque vocatus, inque alis, oculos nomen non silvis corpore coniunx ne displicet illa. Crescunt non unus, vidit visa quantum inmiti flumina mortis facto sic: undique a alios vincula sunt iactata abdita! Suspenderat ego fuit tendit: luna, ante urbem Propoetides parte.\n","date":"2019-03-09T00:00:00Z","image":"https://SilentThink.github.io/p/placeholder-text/matt-le-SJSpo9hQf7s-unsplash_hu10664154974910995856.jpg","permalink":"https://SilentThink.github.io/p/placeholder-text/","title":"Placeholder Text"},{"content":"Mathematical notation in a Hugo project can be enabled by using third party JavaScript libraries.\nIn this example we will be using KaTeX\nCreate a partial under /layouts/partials/math.html Within this partial reference the Auto-render Extension or host these scripts locally. Include the partial in your templates like so: 1 2 3 {{ if or .Params.math .Site.Params.math }} {{ partial \u0026#34;math.html\u0026#34; . }} {{ end }} To enable KaTeX globally set the parameter math to true in a project\u0026rsquo;s configuration To enable KaTeX on a per page basis include the parameter math: true in content files Note: Use the online reference of Supported TeX Functions\nExamples Inline math: $\\varphi = \\dfrac{1+\\sqrt5}{2}= 1.6180339887…$\nBlock math: $$ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$","date":"2019-03-08T00:00:00Z","permalink":"https://SilentThink.github.io/p/math-typesetting/","title":"Math Typesetting"},{"content":"Emoji can be enabled in a Hugo project in a number of ways.\nThe emojify function can be called directly in templates or Inline Shortcodes.\nTo enable emoji globally, set enableEmoji to true in your site\u0026rsquo;s configuration and then you can type emoji shorthand codes directly in content files; e.g.\n🙈 :see_no_evil: 🙉 :hear_no_evil: 🙊 :speak_no_evil:\nThe Emoji cheat sheet is a useful reference for emoji shorthand codes.\nN.B. The above steps enable Unicode Standard emoji characters and sequences in Hugo, however the rendering of these glyphs depends on the browser and the platform. To style the emoji you can either use a third party emoji font or a font stack; e.g.\n1 2 3 .emoji { font-family: Apple Color Emoji, Segoe UI Emoji, NotoColorEmoji, Segoe UI Symbol, Android Emoji, EmojiSymbols; } ","date":"2019-03-05T00:00:00Z","image":"https://SilentThink.github.io/p/emoji-support/the-creative-exchange-d2zvqp3fpro-unsplash_hu5876398126655421130.jpg","permalink":"https://SilentThink.github.io/p/emoji-support/","title":"Emoji Support"}]